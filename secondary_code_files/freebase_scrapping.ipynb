{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell used to get all the different freebase etnictities from our characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the character.metadata.tsv file\n",
    "characters = pd.read_csv('movie_summaries_ada/character.metadata.tsv', sep='\\t', header=None)\n",
    "#define the columns of the character file\n",
    "characters.columns = ['wikipedia_movie_id','freebase_movie_id','movie_release_date','character_name','actor_birth',\n",
    "                      'actor_gender','actor_height','actor_etnicity','actor_name','actor_age_at_release','freebase_char_actor_map_id','freebase_character_id','freebase_actor_id']\n",
    "\n",
    "# list of all unique actor_ethnicity in the character file\n",
    "etnicities = characters.actor_etnicity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: African Americans\n",
      "Description: Americans with sub-Saharan African ancestry\n",
      "/m/0x67 -> African Americans\n",
      "Only Label: African Americans\n"
     ]
    }
   ],
   "source": [
    "def get_link(freebase_id):\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "    query = \"\"\"\n",
    "    SELECT ?item WHERE {\n",
    "      ?item wdt:P646 '\"\"\" + freebase_id + \"\"\"'.\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = requests.get(url, params={'format': 'json', 'query': query})\n",
    "    data = response.json()\n",
    "    results = data['results']['bindings']\n",
    "    if results:\n",
    "        wikidata_entity = results[0]['item']['value'].split('/')[-1]  # Extract Q-code\n",
    "        return wikidata_entity\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "           \n",
    "def get_values(wikidata_entity):\n",
    "    url = \"https://www.wikidata.org/wiki/Special:EntityData/\" + wikidata_entity + \".json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Here you can parse the JSON to extract whatever information you need\n",
    "    # This is a basic example to get the English label and description\n",
    "    entity_data = data['entities'][wikidata_entity]\n",
    "    label = entity_data['labels']['en']['value'] if 'en' in entity_data['labels'] else \"No label\"\n",
    "    description = entity_data['descriptions']['en']['value'] if 'en' in entity_data['descriptions'] else \"No description\"\n",
    "\n",
    "    return label, description\n",
    "\n",
    "def get_label(freebase_id):\n",
    "    wikidata_entity = get_link(freebase_id)\n",
    "    if wikidata_entity:\n",
    "        label, description = get_values(wikidata_entity)\n",
    "        print(freebase_id, \"->\", label)\n",
    "        return label\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "freebase_id = '/m/0x67'  # Replace with your Freebase ID\n",
    "wikidata_entity = get_link(freebase_id)\n",
    "\n",
    "if wikidata_entity:\n",
    "    label, description = get_values(wikidata_entity)\n",
    "    print(\"Label:\", label)\n",
    "    print(\"Description:\", description)\n",
    "else:\n",
    "    print(\"No corresponding Wikidata entity found.\")\n",
    "\n",
    "# Example usage with just the label\n",
    "label = get_label(freebase_id)\n",
    "print(\"Only Label:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etnicities_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freebase_id in etnicities:\n",
    "    wikidata_entity = get_link(freebase_id)\n",
    "    if wikidata_entity:\n",
    "        label, description = get_values(wikidata_entity)\n",
    "        etnicities_dict[freebase_id] = label\n",
    "        print(\"Label:\", label)\n",
    "    else:\n",
    "        print(\"No corresponding Wikidata entity found.\")\n",
    "    time.sleep(1) # sleep for 1 second to avoid hitting the API too quickly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
