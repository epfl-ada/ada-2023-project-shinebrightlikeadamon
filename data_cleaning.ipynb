{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO manage the outliers\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the csv file of actors\n",
    "actors = pd.read_csv('./data/actors.csv')\n",
    "\n",
    "#open the csv file of awards\n",
    "awards = pd.read_csv('./data/data_csv_awards.csv')\n",
    "\n",
    "#open the movie tsv file\n",
    "movies = pd.read_csv('./data/movie_summaries_ada/movie.metadata.tsv', sep='\\t', header=None)\n",
    "#define the columns\n",
    "movies.columns = ['wikipedia_id', 'freebase_id', 'name', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "\n",
    "#open the character.metadata.tsv file\n",
    "characters = pd.read_csv('./data/movie_summaries_ada/character.metadata.tsv', sep='\\t', header=None)\n",
    "#define the columns of the character file\n",
    "characters.columns = ['wikipedia_movie_id','freebase_movie_id','movie_release_date','character_name','actor_birth',\n",
    "                      'actor_gender','actor_height','actor_etnicity','actor_name','actor_age_at_release','freebase_char_actor_map_id','freebase_character_id','freebase_actor_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 81741\n",
      "Number of unique names: 75478\n",
      "Number of unique wiki ids: 81741\n",
      "Number of unique tuples: 81699\n",
      "Number of duplicates: 42\n",
      "New size without duplicates: 81699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timba\\AppData\\Local\\Temp\\ipykernel_19208\\1969108339.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  movies['year_release'] = pd.to_datetime(movies[\"release_date\"], infer_datetime_format=True, errors=\"coerce\").dt.year\n"
     ]
    }
   ],
   "source": [
    "# there are 81741 rows\n",
    "print(\"Original size: \"+str(len(movies['wikipedia_id'])))\n",
    "# check for duplicate wikipedia_id or name, every line is indeed unique but there are duplicates in the name column\n",
    "print(\"Number of unique names: \"+str(len(movies['name'].unique())))\n",
    "print(\"Number of unique wiki ids: \"+str(len(movies['wikipedia_id'].unique())))\n",
    "# show an example of duplicated name, differ in the release date,and runtime\n",
    "#print(movies[movies['name'] == 'The Bridge'])\n",
    "# key identifier is the (name, release_date, runtime) tuple\n",
    "# check for duplicates in the tuple\n",
    "print(\"Number of unique tuples: \"+str(len(movies.groupby(['name','release_date','runtime']))))\n",
    "#show an example of duplicated tuple\n",
    "#print(movies.groupby(['name','release_date','runtime']).size().sort_values(ascending=False).head(7))\n",
    "#effective size is 81699 rows from now on\n",
    "#record the duplicates names in a list\n",
    "duplicates = movies[movies.duplicated(['name','release_date','runtime'])]\n",
    "print(\"Number of duplicates: \"+str(len(duplicates)))\n",
    "#remove the duplicates keeping the row with the highest revenue\n",
    "movies = movies.sort_values('revenue', ascending=False).drop_duplicates(['name','release_date','runtime']).sort_index()\n",
    "print(\"New size without duplicates: \"+str(len(movies['wikipedia_id'])))\n",
    "# need to transform the release_date column to year because of IMBd dataset\n",
    "movies['year_release'] = pd.to_datetime(movies[\"release_date\"], infer_datetime_format=True, errors=\"coerce\").dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaNs in each column: \n",
      "wikipedia_id     0.000000\n",
      "freebase_id      0.000000\n",
      "name             0.000000\n",
      "release_date     8.407692\n",
      "revenue         89.717132\n",
      "runtime         24.986842\n",
      "languages        0.000000\n",
      "countries        0.000000\n",
      "genres           0.000000\n",
      "year_release    51.815812\n",
      "dtype: float64\n",
      "Statistics for revenue: \n",
      "count    8.401000e+03\n",
      "mean     4.799363e+07\n",
      "std      1.121753e+08\n",
      "min      1.000000e+04\n",
      "25%      2.083193e+06\n",
      "50%      1.063969e+07\n",
      "75%      4.071696e+07\n",
      "max      2.782275e+09\n",
      "Name: revenue, dtype: float64\n",
      "Distribution of genres: \n",
      "genres\n",
      "{\"/m/07s9rl0\": \"Drama\"}                                                                                                                                                                     6848\n",
      "{}                                                                                                                                                                                          2288\n",
      "{\"/m/01z4y\": \"Comedy\"}                                                                                                                                                                      2038\n",
      "{\"/m/0jtdp\": \"Documentary\"}                                                                                                                                                                 2000\n",
      "{\"/m/05p553\": \"Comedy film\"}                                                                                                                                                                1384\n",
      "                                                                                                                                                                                            ... \n",
      "{\"/m/0hj3n07\": \"Culture & Society\", \"/m/017fp\": \"Biography\", \"/m/0hj3n4b\": \"Gender Issues\", \"/m/03mqtr\": \"Political drama\", \"/m/075fzd\": \"Social issues\", \"/m/0jtdp\": \"Documentary\"}           1\n",
      "{\"/m/0g092b\": \"Monster movie\", \"/m/06n90\": \"Science Fiction\", \"/m/03npn\": \"Horror\", \"/m/0cq22z7\": \"Sci-Fi Horror\", \"/m/0h9qh\": \"Monster\"}                                                      1\n",
      "{\"/m/0hn10\": \"LGBT\", \"/m/04rlf\": \"Music\", \"/m/02l7c8\": \"Romance Film\", \"/m/07s9rl0\": \"Drama\", \"/m/03q4nz\": \"World cinema\"}                                                                     1\n",
      "{\"/m/06ppq\": \"Silent film\", \"/m/07s9rl0\": \"Drama\", \"/m/03bxz7\": \"Biographical film\", \"/m/0219x_\": \"Indie\"}                                                                                     1\n",
      "{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": \"Japanese Movies\", \"/m/03k9fj\": \"Adventure\", \"/m/0hcr\": \"Animation\", \"/m/02hmvc\": \"Short Film\", \"/m/0jxy\": \"Anime\", \"/m/07s9rl0\": \"Drama\"}       1\n",
      "Name: count, Length: 23814, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for outliers, percentage of NaNs in each column and distributions (min, max, mean, std)\n",
    "# compute percentage of NaNs in each column # Lots of NaN in revenue to be very careful\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(movies.isnull().sum()/len(movies)*100)\n",
    "# compute statistics for revenue\n",
    "print(\"Statistics for revenue: \")\n",
    "print(movies['revenue'].describe())\n",
    "#plot the distribution of revenue with point cloud\n",
    "movies['revenue'].plot(kind='box')\n",
    "\n",
    "# compute the distribution of genres\n",
    "print(\"Distribution of genres: \")\n",
    "print(movies['genres'].value_counts())\n",
    "# There is a lot of subcategories, probably need to group them. 2k NaNs and 6k Drama (3 times as much as next one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size after dropping NaNs: 32663\n"
     ]
    }
   ],
   "source": [
    "# need to drop NaNs in the runtime, release year and name column in order to be able to correctly identify the movies\n",
    "movies = movies.dropna(subset=['runtime','year_release','name'])\n",
    "\n",
    "# runtime is int in IMBd dataset and float in the other one, need to convert it to int with a ceiling\n",
    "movies['runtime'] = movies['runtime'].apply(lambda x: int(math.ceil(x)))\n",
    "# transform the year_release column to int\n",
    "movies['year_release'] = movies['year_release'].astype(int)\n",
    "\n",
    "#print new size of movies (58k)\n",
    "print(\"New size after dropping NaNs: \"+str(len(movies['wikipedia_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timba\\AppData\\Local\\Temp\\ipykernel_19208\\4105059480.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  titles_imbd = pd.read_csv('./data/IMDB/title.basics.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "#load the heavy files aka titles imbd to find the imdb unique id, then use it to find the imdb rating and merge it with the movies dataframe\n",
    "titles_imbd = pd.read_csv('./data/IMDB/title.basics.tsv', sep='\\t')\n",
    "# keep only the columns we need\n",
    "titles_imbd = titles_imbd[['tconst','primaryTitle','startYear','runtimeMinutes']]\n",
    "\n",
    "#load the imdb rating file\n",
    "rating_imbd = pd.read_csv('./data/IMDB/title.ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of titles_imbd: 954198\n"
     ]
    }
   ],
   "source": [
    "#replacing the \\N values with NaN\n",
    "titles_imbd = titles_imbd.replace('\\\\N', pd.NA)\n",
    "#drop the rows with NaN values\n",
    "titles_imbd = titles_imbd.dropna()\n",
    "\n",
    "# convert the startYear and runtimeMinutes column to numbers\n",
    "titles_imbd['startYear'] = titles_imbd['startYear'].astype(int)\n",
    "titles_imbd['runtimeMinutes'] = titles_imbd['runtimeMinutes'].astype(int)\n",
    "\n",
    "# drop duplicates from the titles_imbd dataframe if the tuple (primaryTitle, startYear, runtimeMinutes) is duplicated\n",
    "titles_imbd = titles_imbd.sort_values('runtimeMinutes', ascending=False).drop_duplicates(['primaryTitle','startYear','runtimeMinutes']).sort_index()\n",
    "\n",
    "# merge the ratings_imbd dataframe with the titles_imbd dataframe\n",
    "titles_imbd = titles_imbd.merge(rating_imbd, on='tconst')\n",
    "\n",
    "# show size of the dataframe\n",
    "print(\"Size of titles_imbd: \"+str(len(titles_imbd['tconst'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size after merging with imdb: 32663\n",
      "15106 movies have a rating over 32663 movies, so 46 % movies do have a rating\n",
      "New size after dropping movies without rating: 15106\n",
      "(15106, 12)\n"
     ]
    }
   ],
   "source": [
    "# merge the movies dataframe with the titles_imbd dataframe\n",
    "movies = movies.merge(titles_imbd, left_on=['name','year_release','runtime'], right_on=['primaryTitle','startYear','runtimeMinutes'], how='left')\n",
    "#drop the useless columns\n",
    "movies = movies.drop(columns=['primaryTitle','startYear','runtimeMinutes','tconst'])\n",
    "\n",
    "# show new size of movies after merging with imdb\n",
    "print(\"New size after merging with imdb: \"+str(len(movies['wikipedia_id'])))\n",
    "\n",
    "# 44.4% of the movies have a rating\n",
    "print(str(movies.averageRating.count())+' movies have a rating over '+str(movies.name.count())+' movies, so '+str(round(movies.averageRating.count()*100/movies.name.count()))+' % movies do have a rating')\n",
    "\n",
    "# we drop all the movies that don't have a rating because it is our dependent variable\n",
    "movies = movies.dropna(subset=['averageRating'])\n",
    "\n",
    "# show new size of movies after dropping movies without rating (25k)\n",
    "print(\"New size after dropping movies without rating: \"+str(len(movies['wikipedia_id'])))\n",
    "# show size of the dataframe\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the awards dataframe to only keep the rows with winner as True\n",
    "#awards_winners = awards[awards.winner == True]\n",
    "\n",
    "#filter the awards dataframe to only keep the rows with category containing ACTOR or ACTRESS\n",
    "awards_actors = awards[awards.category.str.contains('ACTOR|ACTRESS')]\n",
    "#awards_winners[awards_winners.category.str.contains('ACTOR|ACTRESS')]\n",
    "\n",
    "#count the number of awards per entity in awards_actors\n",
    "awards_actors_count = awards_actors.groupby('entity',as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134079, 1)\n",
      "(134079, 2)\n",
      "(134079, 3)\n",
      "(134079, 7)\n",
      "1310 actors have a Fame value over 134078 actors, so 1 % actors do have a Fame value\n"
     ]
    }
   ],
   "source": [
    "# get a list of unique actors from the character dataframe\n",
    "actors_list = pd.DataFrame(characters.actor_name.unique())\n",
    "print(actors_list.shape)\n",
    "\n",
    "#rename the column\n",
    "actors_list.columns = ['name']\n",
    "\n",
    "#add a column to the actors_list dataframe with the winners count\n",
    "actors_list = actors_list.merge(awards_actors_count[['entity','winner']], left_on='name', right_on='entity', how='left')\n",
    "#drop the entity column\n",
    "actors_list = actors_list.drop(columns=['entity'])\n",
    "#rename the count column\n",
    "actors_list = actors_list.rename(columns={'winner': 'awards'})\n",
    "#fill the NaN values in the awards column with 0\n",
    "actors_list['awards'] = actors_list['awards'].fillna(0)\n",
    "print(actors_list.shape)\n",
    "\n",
    "#create a dataframe with the number of movies per actor\n",
    "actors_movies_count = pd.DataFrame(characters.actor_name.value_counts())\n",
    "\n",
    "#add a column to the actors_list dataframe with the movies count\n",
    "actors_list = actors_list.merge(actors_movies_count, left_on='name', right_index=True, how='left')\n",
    "#rename the count column\n",
    "actors_list = actors_list.rename(columns={'actor_name': 'movies'})\n",
    "print(actors_list.shape)\n",
    "\n",
    "#replace the Actor column of actors dataframe by the same value but replace each _ by a space\n",
    "actors['Actor'] = actors['Actor'].str.replace('_', ' ')\n",
    "\n",
    "#add the actors dataframe to the actors_list dataframe on the Actor column and name column respectively\n",
    "actors_list = actors_list.merge(actors, left_on='name', right_on='Actor', how='left')\n",
    "\n",
    "#drop the Actor column\n",
    "actors_list = actors_list.drop(columns=['Actor'])\n",
    "print(actors_list.shape)\n",
    "#print the number of actors with a Fame value\n",
    "print(str(actors_list.Fame.count())+' actors have a Fame value over '+str(actors_list.name.count())+' actors, so '+str(round(actors_list.Fame.count()*100/actors_list.name.count()))+' % actors do have a Fame value')\n",
    "#replace the NaN values in the Fame column by 0\n",
    "actors_list['Fame'] = actors_list['Fame'].fillna(0)\n",
    "#replace the NaN values in the Liked,Disliked,Neutral columns by 0\n",
    "actors_list['Liked'] = actors_list['Liked'].fillna(0)\n",
    "actors_list['Disliked'] = actors_list['Disliked'].fillna(0)\n",
    "actors_list['Neutral'] = actors_list['Neutral'].fillna(0)\n",
    "\n",
    "#TODO:issue to solve, we loose about 46 actors in the merge because the name has . or ' or -, and we replace every _ by a space\n",
    "#TODO: possible solution, replace every . or ' or - by a space in the actors_list dataframe\n",
    "#TODO: possible solution, replace every . or ' or - or space by a _ in the actors dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actor_birth actor_gender  actor_height actor_etnicity          actor_name  \\\n",
       "0  1958-08-26            F         1.620            NaN      Wanda De Jesus   \n",
       "1  1974-08-15            F         1.780     /m/044038p  Natasha Henstridge   \n",
       "2  1969-06-15            M         1.727        /m/0x67            Ice Cube   \n",
       "3  1967-09-12            M         1.750            NaN       Jason Statham   \n",
       "4  1977-09-25            F         1.650            NaN         Clea DuVall   \n",
       "\n",
       "  freebase_actor_id  \n",
       "0        /m/03wcfv7  \n",
       "1         /m/0346l4  \n",
       "2        /m/01vw26l  \n",
       "3         /m/034hyc  \n",
       "4         /m/01y9xg  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a pandas dataframe of the characters dataframe with only the first row of each actor\n",
    "actors_metadata = characters.drop_duplicates(subset=['actor_name'], keep='first')\n",
    "#drop the columns that we don't need\n",
    "actors_metadata = actors_metadata.drop(columns=['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name','actor_age_at_release', 'freebase_char_actor_map_id', 'freebase_character_id'])\n",
    "actors_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134079, 12)\n",
      "  actor_birth actor_gender  actor_height actor_etnicity          actor_name  \\\n",
      "0  1958-08-26            F         1.620            NaN      Wanda De Jesus   \n",
      "1  1974-08-15            F         1.780     /m/044038p  Natasha Henstridge   \n",
      "2  1969-06-15            M         1.727        /m/0x67            Ice Cube   \n",
      "3  1967-09-12            M         1.750            NaN       Jason Statham   \n",
      "4  1977-09-25            F         1.650            NaN         Clea DuVall   \n",
      "\n",
      "  freebase_actor_id  awards  count  Fame  Liked  Disliked  Neutral  \n",
      "0        /m/03wcfv7     0.0    8.0   0.0    0.0       0.0      0.0  \n",
      "1         /m/0346l4     0.0   23.0   0.0    0.0       0.0      0.0  \n",
      "2        /m/01vw26l     0.0   33.0  93.0   57.0      11.0     25.0  \n",
      "3         /m/034hyc     0.0   31.0  78.0   59.0       4.0     14.0  \n",
      "4         /m/01y9xg     0.0   31.0   0.0    0.0       0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "actors_info = actors_metadata.merge(actors_list, left_on='actor_name', right_on='name', how='left')\n",
    "actors_info = actors_info.drop(columns=['name'])\n",
    "print(actors_info.shape)\n",
    "print(actors_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaNs in each column: \n",
      "actor_birth          56.755346\n",
      "actor_gender         28.192334\n",
      "actor_height         90.464577\n",
      "actor_etnicity       93.955056\n",
      "actor_name            0.000746\n",
      "freebase_actor_id     0.000746\n",
      "awards                0.000000\n",
      "count                 0.000746\n",
      "Fame                  0.000000\n",
      "Liked                 0.000000\n",
      "Disliked              0.000000\n",
      "Neutral               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show the percentage of NaNs in each column of actors_info\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(actors_info.isnull().sum()/len(actors_info)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size of characters: (450669, 13)\n",
      "New size of the dataset after removing not reviewed movies: (112688, 17)\n",
      "Percentage of NaNs in each column: \n",
      "wikipedia_movie_id             0.000000\n",
      "freebase_movie_id              0.000000\n",
      "movie_release_date             0.000000\n",
      "character_name                42.619445\n",
      "actor_birth                   20.468905\n",
      "actor_gender                   6.935965\n",
      "actor_height                  60.703890\n",
      "actor_etnicity                77.386235\n",
      "actor_name                     0.228063\n",
      "actor_age_at_release          29.151285\n",
      "freebase_char_actor_map_id     0.000000\n",
      "freebase_character_id         42.615895\n",
      "freebase_actor_id              0.166832\n",
      "Fame                           0.000000\n",
      "Liked                          0.000000\n",
      "Disliked                       0.000000\n",
      "Neutral                        0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wikipedia_movie_id freebase_movie_id movie_release_date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "2              975900         /m/03vyhn         2001-08-24   \n",
       "3              975900         /m/03vyhn         2001-08-24   \n",
       "4              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               character_name actor_birth actor_gender  actor_height  \\\n",
       "0                    Akooshay  1958-08-26            F         1.620   \n",
       "1  Lieutenant Melanie Ballard  1974-08-15            F         1.780   \n",
       "2         Desolation Williams  1969-06-15            M         1.727   \n",
       "3          Sgt Jericho Butler  1967-09-12            M         1.750   \n",
       "4             Bashira Kincaid  1977-09-25            F         1.650   \n",
       "\n",
       "  actor_etnicity          actor_name  actor_age_at_release  \\\n",
       "0            NaN      Wanda De Jesus                  42.0   \n",
       "1     /m/044038p  Natasha Henstridge                  27.0   \n",
       "2        /m/0x67            Ice Cube                  32.0   \n",
       "3            NaN       Jason Statham                  33.0   \n",
       "4            NaN         Clea DuVall                  23.0   \n",
       "\n",
       "  freebase_char_actor_map_id freebase_character_id freebase_actor_id  Fame  \\\n",
       "0                 /m/0bgchxw            /m/0bgcj3x        /m/03wcfv7   0.0   \n",
       "1                  /m/0jys3m            /m/0bgchn4         /m/0346l4   0.0   \n",
       "2                  /m/0jys3g            /m/0bgchn_        /m/01vw26l  93.0   \n",
       "3                 /m/02vchl6            /m/0bgchnq         /m/034hyc  78.0   \n",
       "4                 /m/02vbb3r            /m/0bgchp9         /m/01y9xg   0.0   \n",
       "\n",
       "   Liked  Disliked  Neutral  \n",
       "0    0.0       0.0      0.0  \n",
       "1    0.0       0.0      0.0  \n",
       "2   57.0      11.0     25.0  \n",
       "3   59.0       4.0     14.0  \n",
       "4    0.0       0.0      0.0  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show initial size of character dataframe\n",
    "print(\"Initial size of characters: \"+str(characters.shape))\n",
    "# merge additional info of the actors to the characters dataframe\n",
    "characters = characters.merge(actors_list[['name','Fame','Liked','Disliked','Neutral']], left_on='actor_name', right_on='name', how='left')\n",
    "characters = characters.drop(columns=['name'])\n",
    "# show new size of characters dataframe\n",
    "#print(\"New size of the dataset\"+str(characters.shape))\n",
    "# compute percentage of NaNs in each column\n",
    "#print(\"Percentage of NaNs in each column: \")\n",
    "#print(characters.isnull().sum()/len(characters)*100)\n",
    "#etnicty at 76% missing and gender at 10% missing\n",
    "#to re compute if we remove the movies we don't have the rating for\n",
    "\n",
    "# filter out all the character rows which wikipedia_movie_id is not in the movies dataframe\n",
    "characters = characters[characters.wikipedia_movie_id.isin(movies.wikipedia_id)]\n",
    "\n",
    "# show new size of characters dataframe\n",
    "print(\"New size of the dataset after removing not reviewed movies: \"+str(characters.shape))\n",
    "\n",
    "# compute percentage of NaNs in each column\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(characters.isnull().sum()/len(characters)*100)\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of NaN release years before merge: 0\n",
      "Unique cumcounts: [ 1.  2.  3.  4.  7. 10.]\n",
      "#nominations of Katharine Hepburn: year              12\n",
      "category          12\n",
      "winner            12\n",
      "entity            12\n",
      "award_cumcount    12\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    112700.000000\n",
       "mean          0.093407\n",
       "std           0.537816\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          16.000000\n",
       "Name: award_cumcount, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>award_cumcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85188</th>\n",
       "      <td>33028800</td>\n",
       "      <td>/m/0h03fhx</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>Lester Siegel</td>\n",
       "      <td>1934-03-26</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>/m/041rx</td>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>78.0</td>\n",
       "      <td>/m/0h7hx34</td>\n",
       "      <td>/m/0h7hx37</td>\n",
       "      <td>/m/015grj</td>\n",
       "      <td>72.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32261</th>\n",
       "      <td>2223709</td>\n",
       "      <td>/m/06x77g</td>\n",
       "      <td>1977-11-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1931-09-17</td>\n",
       "      <td>F</td>\n",
       "      <td>1.73</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>Anne Bancroft</td>\n",
       "      <td>46.0</td>\n",
       "      <td>/m/02vcmzy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01dbk6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95165</th>\n",
       "      <td>106344</td>\n",
       "      <td>/m/0qmd5</td>\n",
       "      <td>1980-10-03</td>\n",
       "      <td>Mrs. Kendal</td>\n",
       "      <td>1931-09-17</td>\n",
       "      <td>F</td>\n",
       "      <td>1.73</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>Anne Bancroft</td>\n",
       "      <td>49.0</td>\n",
       "      <td>/m/0k4_6w</td>\n",
       "      <td>/m/0hcdrbg</td>\n",
       "      <td>/m/01dbk6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82672</th>\n",
       "      <td>4057650</td>\n",
       "      <td>/m/0bfy61</td>\n",
       "      <td>1983-12-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1931-09-17</td>\n",
       "      <td>F</td>\n",
       "      <td>1.73</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>Anne Bancroft</td>\n",
       "      <td>52.0</td>\n",
       "      <td>/m/02vbcjn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01dbk6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40109</th>\n",
       "      <td>4485134</td>\n",
       "      <td>/m/0c50jq</td>\n",
       "      <td>1984-10-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1931-09-17</td>\n",
       "      <td>F</td>\n",
       "      <td>1.73</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>Anne Bancroft</td>\n",
       "      <td>53.0</td>\n",
       "      <td>/m/0jynt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01dbk6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wikipedia_movie_id freebase_movie_id movie_release_date character_name  \\\n",
       "85188            33028800        /m/0h03fhx         2012-08-31  Lester Siegel   \n",
       "32261             2223709         /m/06x77g         1977-11-14            NaN   \n",
       "95165              106344          /m/0qmd5         1980-10-03    Mrs. Kendal   \n",
       "82672             4057650         /m/0bfy61         1983-12-16            NaN   \n",
       "40109             4485134         /m/0c50jq         1984-10-12            NaN   \n",
       "\n",
       "      actor_birth actor_gender  actor_height actor_etnicity     actor_name  \\\n",
       "85188  1934-03-26            M          1.75       /m/041rx     Alan Arkin   \n",
       "32261  1931-09-17            F          1.73       /m/0xnvg  Anne Bancroft   \n",
       "95165  1931-09-17            F          1.73       /m/0xnvg  Anne Bancroft   \n",
       "82672  1931-09-17            F          1.73       /m/0xnvg  Anne Bancroft   \n",
       "40109  1931-09-17            F          1.73       /m/0xnvg  Anne Bancroft   \n",
       "\n",
       "       actor_age_at_release freebase_char_actor_map_id freebase_character_id  \\\n",
       "85188                  78.0                 /m/0h7hx34            /m/0h7hx37   \n",
       "32261                  46.0                 /m/02vcmzy                   NaN   \n",
       "95165                  49.0                  /m/0k4_6w            /m/0hcdrbg   \n",
       "82672                  52.0                 /m/02vbcjn                   NaN   \n",
       "40109                  53.0                  /m/0jynt2                   NaN   \n",
       "\n",
       "      freebase_actor_id  Fame  Liked  Disliked  Neutral  award_cumcount  \n",
       "85188         /m/015grj  72.0   48.0       5.0     19.0             4.0  \n",
       "32261         /m/01dbk6  70.0   48.0       3.0     18.0             4.0  \n",
       "95165         /m/01dbk6  70.0   48.0       3.0     18.0             4.0  \n",
       "82672         /m/01dbk6  70.0   48.0       3.0     18.0             4.0  \n",
       "40109         /m/01dbk6  70.0   48.0       3.0     18.0             4.0  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cumulative nomination count per actor (nominations until (including) the current award)\n",
    "# TODO Sorting by date? Should be sorted already\n",
    "nominations = awards_actors.copy()\n",
    "nominations['award_cumcount'] = nominations.groupby('entity').cumcount() + 1\n",
    "\n",
    "# Convert 'movie_release_date' to datetime for merging, using coerce for unparseable dates\n",
    "# For rows where conversion failed (resulted in NaT), extract the year directly from the string (often just the year is given)\n",
    "# Leaves rows with no data about movie_release_date as NaT\n",
    "characters['release_year'] = pd.to_datetime(characters['movie_release_date'], errors='coerce').dt.year\n",
    "characters['release_year'] = characters['release_year'].fillna(characters['movie_release_date'].str.extract(r'(\\d{4})')[0].astype(float))\n",
    "\n",
    "#print(characters.release_year.describe()) # TODO Years with 1900 exist.\n",
    "\n",
    "print(f'No. of NaN release years before merge: {characters[\"release_year\"].isna().sum()}')\n",
    "\n",
    "# Merge the DataFrames\n",
    "characters = pd.merge(characters, \n",
    "                     nominations[['entity', 'year', 'award_cumcount']], \n",
    "                     left_on=['actor_name', 'release_year'],\n",
    "                     right_on=['entity', 'year'], \n",
    "                     how='left')\n",
    "\n",
    "# Forward fill 'award_cumcount' within each 'actor_name' group for following years till next award\n",
    "characters = characters.sort_values(by=['actor_name', 'movie_release_date'])\n",
    "characters['award_cumcount'] = characters.groupby('actor_name')['award_cumcount'].ffill()\n",
    "\n",
    "# TODO include in markdown: The difference in the following numbers results from dropped rows (cause movie not in other movie dataset)\n",
    "print(f'Unique cumcounts: {characters[(characters.actor_name == \"Katharine Hepburn\")][\"award_cumcount\"].unique()}')\n",
    "print(f'#nominations of Katharine Hepburn: {nominations[nominations[\"entity\"] == \"Katharine Hepburn\"].count()}')\n",
    "\n",
    "# After the above steps, 'award_cumcount' will still have NaNs for characters whose actors have no award or\n",
    "# until the year of the first award. We replace these NaNs with 0.\n",
    "characters['award_cumcount'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop the extra columns\n",
    "characters.drop(columns=['entity', 'release_year', 'year'], inplace=True)\n",
    "\n",
    "display(characters.award_cumcount.describe())\n",
    "characters[characters.award_cumcount == 4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of NaNs in movies_cumcount column: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    112512.000000\n",
       "mean          2.777162\n",
       "std           5.021171\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           3.000000\n",
       "max          93.000000\n",
       "Name: movies_cumcount, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>award_cumcount</th>\n",
       "      <th>movies_cumcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47745</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47746</th>\n",
       "      <td>2976107</td>\n",
       "      <td>/m/08h5ny</td>\n",
       "      <td>2003-05-30</td>\n",
       "      <td>Handsome Rob</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>35.0</td>\n",
       "      <td>/m/02l07sm</td>\n",
       "      <td>/m/0c1nyzc</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47747</th>\n",
       "      <td>826409</td>\n",
       "      <td>/m/03f7nt</td>\n",
       "      <td>2004-08-05</td>\n",
       "      <td>Airport Man</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>36.0</td>\n",
       "      <td>/m/03jps0r</td>\n",
       "      <td>/m/0c1lxk3</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47748</th>\n",
       "      <td>2409484</td>\n",
       "      <td>/m/07b2jc</td>\n",
       "      <td>2005-08-03</td>\n",
       "      <td>Frank Martin</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>37.0</td>\n",
       "      <td>/m/0k79lk</td>\n",
       "      <td>/m/026yqk6</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47749</th>\n",
       "      <td>2581392</td>\n",
       "      <td>/m/07phbc</td>\n",
       "      <td>2006-01-19</td>\n",
       "      <td>Yves Gluant</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>38.0</td>\n",
       "      <td>/m/03jrscm</td>\n",
       "      <td>/m/0gghg36</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47750</th>\n",
       "      <td>5795788</td>\n",
       "      <td>/m/0f52ld</td>\n",
       "      <td>2007-08-24</td>\n",
       "      <td>Crawford</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/m/02vbscv</td>\n",
       "      <td>/m/0gxf16_</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47751</th>\n",
       "      <td>12160883</td>\n",
       "      <td>/m/02vrt_0</td>\n",
       "      <td>2008-02-19</td>\n",
       "      <td>Terry Leather</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>40.0</td>\n",
       "      <td>/m/03jqy9j</td>\n",
       "      <td>/m/0b_nq1h</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47752</th>\n",
       "      <td>14708304</td>\n",
       "      <td>/m/03gtwh_</td>\n",
       "      <td>2009-04-16</td>\n",
       "      <td>Chev Chelios</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>41.0</td>\n",
       "      <td>/m/04m74xb</td>\n",
       "      <td>/m/0410ywf</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47753</th>\n",
       "      <td>27203385</td>\n",
       "      <td>/m/0bwj49p</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>Arthur Bishop</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>43.0</td>\n",
       "      <td>/m/0cs288l</td>\n",
       "      <td>/m/0g4qhw2</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47754</th>\n",
       "      <td>33276254</td>\n",
       "      <td>/m/0gffmn8</td>\n",
       "      <td>2012-08-08</td>\n",
       "      <td>Lee Christmas</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>44.0</td>\n",
       "      <td>/m/0gwhct9</td>\n",
       "      <td>/m/08ldsbl</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wikipedia_movie_id freebase_movie_id movie_release_date  \\\n",
       "47745              975900         /m/03vyhn         2001-08-24   \n",
       "47746             2976107         /m/08h5ny         2003-05-30   \n",
       "47747              826409         /m/03f7nt         2004-08-05   \n",
       "47748             2409484         /m/07b2jc         2005-08-03   \n",
       "47749             2581392         /m/07phbc         2006-01-19   \n",
       "47750             5795788         /m/0f52ld         2007-08-24   \n",
       "47751            12160883        /m/02vrt_0         2008-02-19   \n",
       "47752            14708304        /m/03gtwh_         2009-04-16   \n",
       "47753            27203385        /m/0bwj49p         2011-01-13   \n",
       "47754            33276254        /m/0gffmn8         2012-08-08   \n",
       "\n",
       "           character_name actor_birth actor_gender  actor_height  \\\n",
       "47745  Sgt Jericho Butler  1967-09-12            M          1.75   \n",
       "47746        Handsome Rob  1967-09-12            M          1.75   \n",
       "47747         Airport Man  1967-09-12            M          1.75   \n",
       "47748        Frank Martin  1967-09-12            M          1.75   \n",
       "47749         Yves Gluant  1967-09-12            M          1.75   \n",
       "47750            Crawford  1967-09-12            M          1.75   \n",
       "47751       Terry Leather  1967-09-12            M          1.75   \n",
       "47752        Chev Chelios  1967-09-12            M          1.75   \n",
       "47753       Arthur Bishop  1967-09-12            M          1.75   \n",
       "47754       Lee Christmas  1967-09-12            M          1.75   \n",
       "\n",
       "      actor_etnicity     actor_name  actor_age_at_release  \\\n",
       "47745            NaN  Jason Statham                  33.0   \n",
       "47746            NaN  Jason Statham                  35.0   \n",
       "47747            NaN  Jason Statham                  36.0   \n",
       "47748            NaN  Jason Statham                  37.0   \n",
       "47749            NaN  Jason Statham                  38.0   \n",
       "47750            NaN  Jason Statham                  39.0   \n",
       "47751            NaN  Jason Statham                  40.0   \n",
       "47752            NaN  Jason Statham                  41.0   \n",
       "47753            NaN  Jason Statham                  43.0   \n",
       "47754            NaN  Jason Statham                  44.0   \n",
       "\n",
       "      freebase_char_actor_map_id freebase_character_id freebase_actor_id  \\\n",
       "47745                 /m/02vchl6            /m/0bgchnq         /m/034hyc   \n",
       "47746                 /m/02l07sm            /m/0c1nyzc         /m/034hyc   \n",
       "47747                 /m/03jps0r            /m/0c1lxk3         /m/034hyc   \n",
       "47748                  /m/0k79lk            /m/026yqk6         /m/034hyc   \n",
       "47749                 /m/03jrscm            /m/0gghg36         /m/034hyc   \n",
       "47750                 /m/02vbscv            /m/0gxf16_         /m/034hyc   \n",
       "47751                 /m/03jqy9j            /m/0b_nq1h         /m/034hyc   \n",
       "47752                 /m/04m74xb            /m/0410ywf         /m/034hyc   \n",
       "47753                 /m/0cs288l            /m/0g4qhw2         /m/034hyc   \n",
       "47754                 /m/0gwhct9            /m/08ldsbl         /m/034hyc   \n",
       "\n",
       "       Fame  Liked  Disliked  Neutral  award_cumcount  movies_cumcount  \n",
       "47745  78.0   59.0       4.0     14.0             0.0              0.0  \n",
       "47746  78.0   59.0       4.0     14.0             0.0              1.0  \n",
       "47747  78.0   59.0       4.0     14.0             0.0              2.0  \n",
       "47748  78.0   59.0       4.0     14.0             0.0              3.0  \n",
       "47749  78.0   59.0       4.0     14.0             0.0              4.0  \n",
       "47750  78.0   59.0       4.0     14.0             0.0              5.0  \n",
       "47751  78.0   59.0       4.0     14.0             0.0              6.0  \n",
       "47752  78.0   59.0       4.0     14.0             0.0              7.0  \n",
       "47753  78.0   59.0       4.0     14.0             0.0              8.0  \n",
       "47754  78.0   59.0       4.0     14.0             0.0              9.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add Movie Experience\n",
    "# 1. Clean: Extract Movies from character based df into new df and drop duplicates\n",
    "# 2. Calc cumcount per actor in this seperate df\n",
    "# 3. Left Join seperate df onto original df!\n",
    "# 4. Drop roles of movies we don't look at!\n",
    "\n",
    "# TODO Note in markdown: Assumption: One Movie and not one role counts as one experience.\n",
    "\n",
    "# Copy to work on separate df that we can modify and clean.\n",
    "characters_movie_exp = characters.copy()\n",
    "\n",
    "# Drop characters with no unique identifier for an actor\n",
    "characters_movie_exp = characters_movie_exp.dropna(subset=['freebase_actor_id'])\n",
    "\n",
    "assert characters_movie_exp.freebase_actor_id.isna().sum() == 0, \"Some actors don't have an id\"\n",
    "assert characters_movie_exp.freebase_movie_id.isna().sum() == 0, \"Some movies don't have an id\"\n",
    "\n",
    "# Drop actors that played twice in the same movie\n",
    "characters_movie_exp = characters_movie_exp.drop_duplicates(['freebase_movie_id', 'freebase_actor_id'])\n",
    "\n",
    "#  Get cumulative movie count per actor (movies done until (excluding) the current movie) as a measure of prior experience\n",
    "characters_movie_exp = characters_movie_exp.sort_values(by=['freebase_actor_id', 'movie_release_date'])\n",
    "characters_movie_exp['movies_cumcount'] = characters_movie_exp.groupby(['freebase_actor_id']).cumcount()\n",
    "\n",
    "characters = pd.merge(characters,\n",
    "                    characters_movie_exp[['freebase_movie_id', 'freebase_actor_id', 'movies_cumcount']],\n",
    "                    on=['freebase_movie_id', 'freebase_actor_id'],\n",
    "                    how='left' )\n",
    "\n",
    "# Ensure we have data about the same set of movies to ensure comparability of findings\n",
    "characters = characters[characters['freebase_movie_id'].isin(movies.freebase_id)].copy()\n",
    "\n",
    "characters = characters.sort_values(by=['freebase_actor_id', 'movie_release_date'])\n",
    "characters['movies_cumcount'] = characters.groupby('freebase_actor_id')['movies_cumcount'].ffill()\n",
    "\n",
    "# Drop characters without a name and freebase id. This effectifely drops all NaN movies_cumcount's, as these NaN's were the reason.\n",
    "characters = characters.dropna(subset=['freebase_actor_id', 'actor_name'], how='all')\n",
    "print(f'Sum of NaNs in movies_cumcount column: {characters.movies_cumcount.isna().sum()}')\n",
    "\n",
    "display(characters.movies_cumcount.describe())\n",
    "characters.head()\n",
    "display(characters[characters.actor_name == 'Jason Statham'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update of actors dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of the dataset after removing actors not in characters: (51085, 12)\n",
      "Percentage of NaNs in each column: \n",
      "actor_birth          39.665264\n",
      "actor_gender         13.845552\n",
      "actor_height         82.307918\n",
      "actor_etnicity       89.493981\n",
      "actor_name            0.001958\n",
      "freebase_actor_id     0.001958\n",
      "awards                0.000000\n",
      "count                 0.001958\n",
      "Fame                  0.000000\n",
      "Liked                 0.000000\n",
      "Disliked              0.000000\n",
      "Neutral               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# filter out actors in actors_info that are not in the characters dataframe\n",
    "actors_info_test = actors_info[actors_info.actor_name.isin(characters.actor_name)]\n",
    "# show new size of actors_info dataframe\n",
    "print(\"New size of the dataset after removing actors not in characters: \"+str(actors_info_test.shape))\n",
    "\n",
    "# compute percentage of NaNs in each column\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(actors_info_test.isnull().sum()/len(actors_info_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update of Movies dataset:\n",
    "Adding character info summarized per movie to complete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1355 entries, 0 to 1354\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Actor     1355 non-null   object\n",
      " 1   Fame      1355 non-null   int64 \n",
      " 2   Liked     1355 non-null   int64 \n",
      " 3   Disliked  1355 non-null   int64 \n",
      " 4   Neutral   1355 non-null   int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 53.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11058 entries, 0 to 11057\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   year      11058 non-null  int64 \n",
      " 1   category  11058 non-null  object\n",
      " 2   winner    11058 non-null  bool  \n",
      " 3   entity    11058 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 270.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15106 entries, 0 to 32661\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   wikipedia_id   15106 non-null  int64  \n",
      " 1   freebase_id    15106 non-null  object \n",
      " 2   name           15106 non-null  object \n",
      " 3   release_date   15106 non-null  object \n",
      " 4   revenue        3308 non-null   float64\n",
      " 5   runtime        15106 non-null  int64  \n",
      " 6   languages      15106 non-null  object \n",
      " 7   countries      15106 non-null  object \n",
      " 8   genres         15106 non-null  object \n",
      " 9   year_release   15106 non-null  int32  \n",
      " 10  averageRating  15106 non-null  float64\n",
      " 11  numVotes       15106 non-null  float64\n",
      "dtypes: float64(3), int32(1), int64(2), object(6)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112512 entries, 355 to 83073\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   wikipedia_movie_id          112512 non-null  int64  \n",
      " 1   freebase_movie_id           112512 non-null  object \n",
      " 2   movie_release_date          112512 non-null  object \n",
      " 3   character_name              64577 non-null   object \n",
      " 4   actor_birth                 89634 non-null   object \n",
      " 5   actor_gender                104884 non-null  object \n",
      " 6   actor_height                44292 non-null   float64\n",
      " 7   actor_etnicity              25491 non-null   object \n",
      " 8   actor_name                  112443 non-null  object \n",
      " 9   actor_age_at_release        79848 non-null   float64\n",
      " 10  freebase_char_actor_map_id  112512 non-null  object \n",
      " 11  freebase_character_id       64581 non-null   object \n",
      " 12  freebase_actor_id           112512 non-null  object \n",
      " 13  Fame                        112512 non-null  float64\n",
      " 14  Liked                       112512 non-null  float64\n",
      " 15  Disliked                    112512 non-null  float64\n",
      " 16  Neutral                     112512 non-null  float64\n",
      " 17  award_cumcount              112512 non-null  float64\n",
      " 18  movies_cumcount             112512 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(10)\n",
      "memory usage: 17.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# basic info of the data to see changes when cleaning\n",
    "print(actors.info())\n",
    "print(awards.info())\n",
    "print(movies.info())\n",
    "print(characters.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
