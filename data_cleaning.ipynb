{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO manage the outliers\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the csv file of actors\n",
    "actors = pd.read_csv('./data/actors.csv')\n",
    "\n",
    "#open the csv file of awards\n",
    "awards = pd.read_csv('./data/data_csv_awards.csv')\n",
    "\n",
    "#open the movie tsv file\n",
    "movies = pd.read_csv('./data/movie_summaries_ada/movie.metadata.tsv', sep='\\t', header=None)\n",
    "#define the columns\n",
    "movies.columns = ['wikipedia_id', 'freebase_id', 'name', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "\n",
    "#open the character.metadata.tsv file\n",
    "characters = pd.read_csv('./data/movie_summaries_ada/character.metadata.tsv', sep='\\t', header=None)\n",
    "#define the columns of the character file\n",
    "characters.columns = ['wikipedia_movie_id','freebase_movie_id','movie_release_date','character_name','actor_birth',\n",
    "                      'actor_gender','actor_height','actor_etnicity','actor_name','actor_age_at_release','freebase_char_actor_map_id','freebase_character_id','freebase_actor_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 81741\n",
      "Number of unique names: 75478\n",
      "Number of unique wiki ids: 81741\n",
      "Number of unique tuples: 81699\n",
      "Number of duplicates: 42\n",
      "New size without duplicates: 81699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timba\\AppData\\Local\\Temp\\ipykernel_12340\\1969108339.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  movies['year_release'] = pd.to_datetime(movies[\"release_date\"], infer_datetime_format=True, errors=\"coerce\").dt.year\n"
     ]
    }
   ],
   "source": [
    "# there are 81741 rows\n",
    "print(\"Original size: \"+str(len(movies['wikipedia_id'])))\n",
    "# check for duplicate wikipedia_id or name, every line is indeed unique but there are duplicates in the name column\n",
    "print(\"Number of unique names: \"+str(len(movies['name'].unique())))\n",
    "print(\"Number of unique wiki ids: \"+str(len(movies['wikipedia_id'].unique())))\n",
    "# show an example of duplicated name, differ in the release date,and runtime\n",
    "#print(movies[movies['name'] == 'The Bridge'])\n",
    "# key identifier is the (name, release_date, runtime) tuple\n",
    "# check for duplicates in the tuple\n",
    "print(\"Number of unique tuples: \"+str(len(movies.groupby(['name','release_date','runtime']))))\n",
    "#show an example of duplicated tuple\n",
    "#print(movies.groupby(['name','release_date','runtime']).size().sort_values(ascending=False).head(7))\n",
    "#effective size is 81699 rows from now on\n",
    "#record the duplicates names in a list\n",
    "duplicates = movies[movies.duplicated(['name','release_date','runtime'])]\n",
    "print(\"Number of duplicates: \"+str(len(duplicates)))\n",
    "#remove the duplicates keeping the row with the highest revenue\n",
    "movies = movies.sort_values('revenue', ascending=False).drop_duplicates(['name','release_date','runtime']).sort_index()\n",
    "print(\"New size without duplicates: \"+str(len(movies['wikipedia_id'])))\n",
    "# need to transform the release_date column to year because of IMBd dataset\n",
    "movies['year_release'] = pd.to_datetime(movies[\"release_date\"], infer_datetime_format=True, errors=\"coerce\").dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaNs in each column: \n",
      "wikipedia_id     0.000000\n",
      "freebase_id      0.000000\n",
      "name             0.000000\n",
      "release_date     8.407692\n",
      "revenue         89.717132\n",
      "runtime         24.986842\n",
      "languages        0.000000\n",
      "countries        0.000000\n",
      "genres           0.000000\n",
      "year_release    51.815812\n",
      "dtype: float64\n",
      "Statistics for revenue: \n",
      "count    8.401000e+03\n",
      "mean     4.799363e+07\n",
      "std      1.121753e+08\n",
      "min      1.000000e+04\n",
      "25%      2.083193e+06\n",
      "50%      1.063969e+07\n",
      "75%      4.071696e+07\n",
      "max      2.782275e+09\n",
      "Name: revenue, dtype: float64\n",
      "Distribution of genres: \n",
      "genres\n",
      "{\"/m/07s9rl0\": \"Drama\"}                                                                                                                                                                     6848\n",
      "{}                                                                                                                                                                                          2288\n",
      "{\"/m/01z4y\": \"Comedy\"}                                                                                                                                                                      2038\n",
      "{\"/m/0jtdp\": \"Documentary\"}                                                                                                                                                                 2000\n",
      "{\"/m/05p553\": \"Comedy film\"}                                                                                                                                                                1384\n",
      "                                                                                                                                                                                            ... \n",
      "{\"/m/0hj3n07\": \"Culture & Society\", \"/m/017fp\": \"Biography\", \"/m/0hj3n4b\": \"Gender Issues\", \"/m/03mqtr\": \"Political drama\", \"/m/075fzd\": \"Social issues\", \"/m/0jtdp\": \"Documentary\"}           1\n",
      "{\"/m/0g092b\": \"Monster movie\", \"/m/06n90\": \"Science Fiction\", \"/m/03npn\": \"Horror\", \"/m/0cq22z7\": \"Sci-Fi Horror\", \"/m/0h9qh\": \"Monster\"}                                                      1\n",
      "{\"/m/0hn10\": \"LGBT\", \"/m/04rlf\": \"Music\", \"/m/02l7c8\": \"Romance Film\", \"/m/07s9rl0\": \"Drama\", \"/m/03q4nz\": \"World cinema\"}                                                                     1\n",
      "{\"/m/06ppq\": \"Silent film\", \"/m/07s9rl0\": \"Drama\", \"/m/03bxz7\": \"Biographical film\", \"/m/0219x_\": \"Indie\"}                                                                                     1\n",
      "{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": \"Japanese Movies\", \"/m/03k9fj\": \"Adventure\", \"/m/0hcr\": \"Animation\", \"/m/02hmvc\": \"Short Film\", \"/m/0jxy\": \"Anime\", \"/m/07s9rl0\": \"Drama\"}       1\n",
      "Name: count, Length: 23814, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for outliers, percentage of NaNs in each column and distributions (min, max, mean, std)\n",
    "# compute percentage of NaNs in each column # Lots of NaN in revenue to be very careful\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(movies.isnull().sum()/len(movies)*100)\n",
    "# compute statistics for revenue\n",
    "print(\"Statistics for revenue: \")\n",
    "print(movies['revenue'].describe())\n",
    "#plot the distribution of revenue with point cloud\n",
    "movies['revenue'].plot(kind='box')\n",
    "\n",
    "# compute the distribution of genres\n",
    "print(\"Distribution of genres: \")\n",
    "print(movies['genres'].value_counts())\n",
    "# There is a lot of subcategories, probably need to group them. 2k NaNs and 6k Drama (3 times as much as next one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size after dropping NaNs: 32663\n"
     ]
    }
   ],
   "source": [
    "# need to drop NaNs in the runtime, release year and name column in order to be able to correctly identify the movies\n",
    "movies = movies.dropna(subset=['runtime','year_release','name'])\n",
    "\n",
    "# runtime is int in IMBd dataset and float in the other one, need to convert it to int with a ceiling\n",
    "movies['runtime'] = movies['runtime'].apply(lambda x: int(math.ceil(x)))\n",
    "# transform the year_release column to int\n",
    "movies['year_release'] = movies['year_release'].astype(int)\n",
    "\n",
    "#print new size of movies (58k)\n",
    "print(\"New size after dropping NaNs: \"+str(len(movies['wikipedia_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timba\\AppData\\Local\\Temp\\ipykernel_12340\\4105059480.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  titles_imbd = pd.read_csv('./data/IMDB/title.basics.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "#load the heavy files aka titles imbd to find the imdb unique id, then use it to find the imdb rating and merge it with the movies dataframe\n",
    "titles_imbd = pd.read_csv('./data/IMDB/title.basics.tsv', sep='\\t')\n",
    "# keep only the columns we need\n",
    "titles_imbd = titles_imbd[['tconst','primaryTitle','startYear','runtimeMinutes']]\n",
    "\n",
    "#load the imdb rating file\n",
    "rating_imbd = pd.read_csv('./data/IMDB/title.ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of titles_imbd: 954198\n"
     ]
    }
   ],
   "source": [
    "#replacing the \\N values with NaN\n",
    "titles_imbd = titles_imbd.replace('\\\\N', pd.NA)\n",
    "#drop the rows with NaN values\n",
    "titles_imbd = titles_imbd.dropna()\n",
    "\n",
    "# convert the startYear and runtimeMinutes column to numbers\n",
    "titles_imbd['startYear'] = titles_imbd['startYear'].astype(int)\n",
    "titles_imbd['runtimeMinutes'] = titles_imbd['runtimeMinutes'].astype(int)\n",
    "\n",
    "# drop duplicates from the titles_imbd dataframe if the tuple (primaryTitle, startYear, runtimeMinutes) is duplicated\n",
    "titles_imbd = titles_imbd.sort_values('runtimeMinutes', ascending=False).drop_duplicates(['primaryTitle','startYear','runtimeMinutes']).sort_index()\n",
    "\n",
    "# merge the ratings_imbd dataframe with the titles_imbd dataframe\n",
    "titles_imbd = titles_imbd.merge(rating_imbd, on='tconst')\n",
    "\n",
    "# show size of the dataframe\n",
    "print(\"Size of titles_imbd: \"+str(len(titles_imbd['tconst'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size after merging with imdb: 32663\n",
      "15106 movies have a rating over 32663 movies, so 46 % movies do have a rating\n",
      "New size after dropping movies without rating: 15106\n",
      "(15106, 12)\n"
     ]
    }
   ],
   "source": [
    "# merge the movies dataframe with the titles_imbd dataframe\n",
    "movies = movies.merge(titles_imbd, left_on=['name','year_release','runtime'], right_on=['primaryTitle','startYear','runtimeMinutes'], how='left')\n",
    "#drop the useless columns\n",
    "movies = movies.drop(columns=['primaryTitle','startYear','runtimeMinutes','tconst'])\n",
    "\n",
    "# show new size of movies after merging with imdb\n",
    "print(\"New size after merging with imdb: \"+str(len(movies['wikipedia_id'])))\n",
    "\n",
    "# 44.4% of the movies have a rating\n",
    "print(str(movies.averageRating.count())+' movies have a rating over '+str(movies.name.count())+' movies, so '+str(round(movies.averageRating.count()*100/movies.name.count()))+' % movies do have a rating')\n",
    "\n",
    "# we drop all the movies that don't have a rating because it is our dependent variable\n",
    "movies = movies.dropna(subset=['averageRating'])\n",
    "\n",
    "# show new size of movies after dropping movies without rating (25k)\n",
    "print(\"New size after dropping movies without rating: \"+str(len(movies['wikipedia_id'])))\n",
    "# show size of the dataframe\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the awards dataframe to only keep the rows with winner as True\n",
    "#awards_winners = awards[awards.winner == True]\n",
    "\n",
    "#filter the awards dataframe to only keep the rows with category containing ACTOR or ACTRESS\n",
    "awards_actors = awards[awards.category.str.contains('ACTOR|ACTRESS')]\n",
    "#awards_winners[awards_winners.category.str.contains('ACTOR|ACTRESS')]\n",
    "\n",
    "#count the number of awards per entity in awards_actors\n",
    "awards_actors_count = awards_actors.groupby('entity',as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134079, 1)\n",
      "(134079, 2)\n",
      "(134079, 3)\n",
      "(134079, 7)\n",
      "1310 actors have a Fame value over 134078 actors, so 1 % actors do have a Fame value\n"
     ]
    }
   ],
   "source": [
    "# get a list of unique actors from the character dataframe\n",
    "actors_list = pd.DataFrame(characters.actor_name.unique())\n",
    "print(actors_list.shape)\n",
    "\n",
    "#rename the column\n",
    "actors_list.columns = ['name']\n",
    "\n",
    "#add a column to the actors_list dataframe with the winners count\n",
    "actors_list = actors_list.merge(awards_actors_count[['entity','winner']], left_on='name', right_on='entity', how='left')\n",
    "#drop the entity column\n",
    "actors_list = actors_list.drop(columns=['entity'])\n",
    "#rename the count column\n",
    "actors_list = actors_list.rename(columns={'winner': 'awards'})\n",
    "#fill the NaN values in the awards column with 0\n",
    "actors_list['awards'] = actors_list['awards'].fillna(0)\n",
    "print(actors_list.shape)\n",
    "\n",
    "#create a dataframe with the number of movies per actor\n",
    "actors_movies_count = pd.DataFrame(characters.actor_name.value_counts())\n",
    "\n",
    "#add a column to the actors_list dataframe with the movies count\n",
    "actors_list = actors_list.merge(actors_movies_count, left_on='name', right_index=True, how='left')\n",
    "#rename the count column\n",
    "actors_list = actors_list.rename(columns={'actor_name': 'movies'})\n",
    "print(actors_list.shape)\n",
    "\n",
    "#replace the Actor column of actors dataframe by the same value but replace each _ by a space\n",
    "actors['Actor'] = actors['Actor'].str.replace('_', ' ')\n",
    "\n",
    "#add the actors dataframe to the actors_list dataframe on the Actor column and name column respectively\n",
    "actors_list = actors_list.merge(actors, left_on='name', right_on='Actor', how='left')\n",
    "\n",
    "#drop the Actor column\n",
    "actors_list = actors_list.drop(columns=['Actor'])\n",
    "print(actors_list.shape)\n",
    "#print the number of actors with a Fame value\n",
    "print(str(actors_list.Fame.count())+' actors have a Fame value over '+str(actors_list.name.count())+' actors, so '+str(round(actors_list.Fame.count()*100/actors_list.name.count()))+' % actors do have a Fame value')\n",
    "#replace the NaN values in the Fame column by 0\n",
    "actors_list['Fame'] = actors_list['Fame'].fillna(0)\n",
    "#replace the NaN values in the Liked,Disliked,Neutral columns by 0\n",
    "actors_list['Liked'] = actors_list['Liked'].fillna(0)\n",
    "actors_list['Disliked'] = actors_list['Disliked'].fillna(0)\n",
    "actors_list['Neutral'] = actors_list['Neutral'].fillna(0)\n",
    "\n",
    "#TODO:issue to solve, we loose about 46 actors in the merge because the name has . or ' or -, and we replace every _ by a space\n",
    "#TODO: possible solution, replace every . or ' or - by a space in the actors_list dataframe\n",
    "#TODO: possible solution, replace every . or ' or - or space by a _ in the actors dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actor_birth actor_gender  actor_height actor_etnicity          actor_name  \\\n",
       "0  1958-08-26            F         1.620            NaN      Wanda De Jesus   \n",
       "1  1974-08-15            F         1.780     /m/044038p  Natasha Henstridge   \n",
       "2  1969-06-15            M         1.727        /m/0x67            Ice Cube   \n",
       "3  1967-09-12            M         1.750            NaN       Jason Statham   \n",
       "4  1977-09-25            F         1.650            NaN         Clea DuVall   \n",
       "\n",
       "  freebase_actor_id  \n",
       "0        /m/03wcfv7  \n",
       "1         /m/0346l4  \n",
       "2        /m/01vw26l  \n",
       "3         /m/034hyc  \n",
       "4         /m/01y9xg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a pandas dataframe of the characters dataframe with only the first row of each actor\n",
    "actors_metadata = characters.drop_duplicates(subset=['actor_name'], keep='first')\n",
    "#drop the columns that we don't need\n",
    "actors_metadata = actors_metadata.drop(columns=['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date', 'character_name','actor_age_at_release', 'freebase_char_actor_map_id', 'freebase_character_id'])\n",
    "actors_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134079, 12)\n",
      "  actor_birth actor_gender  actor_height actor_etnicity          actor_name  \\\n",
      "0  1958-08-26            F         1.620            NaN      Wanda De Jesus   \n",
      "1  1974-08-15            F         1.780     /m/044038p  Natasha Henstridge   \n",
      "2  1969-06-15            M         1.727        /m/0x67            Ice Cube   \n",
      "3  1967-09-12            M         1.750            NaN       Jason Statham   \n",
      "4  1977-09-25            F         1.650            NaN         Clea DuVall   \n",
      "\n",
      "  freebase_actor_id  awards  count  Fame  Liked  Disliked  Neutral  \n",
      "0        /m/03wcfv7     0.0    8.0   0.0    0.0       0.0      0.0  \n",
      "1         /m/0346l4     0.0   23.0   0.0    0.0       0.0      0.0  \n",
      "2        /m/01vw26l     0.0   33.0  93.0   57.0      11.0     25.0  \n",
      "3         /m/034hyc     0.0   31.0  78.0   59.0       4.0     14.0  \n",
      "4         /m/01y9xg     0.0   31.0   0.0    0.0       0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "actors_info = actors_metadata.merge(actors_list, left_on='actor_name', right_on='name', how='left')\n",
    "actors_info = actors_info.drop(columns=['name'])\n",
    "print(actors_info.shape)\n",
    "print(actors_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaNs in each column: \n",
      "actor_birth          56.755346\n",
      "actor_gender         28.192334\n",
      "actor_height         90.464577\n",
      "actor_etnicity       93.955056\n",
      "actor_name            0.000746\n",
      "freebase_actor_id     0.000746\n",
      "awards                0.000000\n",
      "count                 0.000746\n",
      "Fame                  0.000000\n",
      "Liked                 0.000000\n",
      "Disliked              0.000000\n",
      "Neutral               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show the percentage of NaNs in each column of actors_info\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(actors_info.isnull().sum()/len(actors_info)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size of characters: (450669, 13)\n",
      "New size of the dataset after removing not reviewed movies: (112688, 17)\n",
      "Percentage of NaNs in each column: \n",
      "wikipedia_movie_id             0.000000\n",
      "freebase_movie_id              0.000000\n",
      "movie_release_date             0.000000\n",
      "character_name                42.619445\n",
      "actor_birth                   20.468905\n",
      "actor_gender                   6.935965\n",
      "actor_height                  60.703890\n",
      "actor_etnicity                77.386235\n",
      "actor_name                     0.228063\n",
      "actor_age_at_release          29.151285\n",
      "freebase_char_actor_map_id     0.000000\n",
      "freebase_character_id         42.615895\n",
      "freebase_actor_id              0.166832\n",
      "Fame                           0.000000\n",
      "Liked                          0.000000\n",
      "Disliked                       0.000000\n",
      "Neutral                        0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wikipedia_movie_id freebase_movie_id movie_release_date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "2              975900         /m/03vyhn         2001-08-24   \n",
       "3              975900         /m/03vyhn         2001-08-24   \n",
       "4              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               character_name actor_birth actor_gender  actor_height  \\\n",
       "0                    Akooshay  1958-08-26            F         1.620   \n",
       "1  Lieutenant Melanie Ballard  1974-08-15            F         1.780   \n",
       "2         Desolation Williams  1969-06-15            M         1.727   \n",
       "3          Sgt Jericho Butler  1967-09-12            M         1.750   \n",
       "4             Bashira Kincaid  1977-09-25            F         1.650   \n",
       "\n",
       "  actor_etnicity          actor_name  actor_age_at_release  \\\n",
       "0            NaN      Wanda De Jesus                  42.0   \n",
       "1     /m/044038p  Natasha Henstridge                  27.0   \n",
       "2        /m/0x67            Ice Cube                  32.0   \n",
       "3            NaN       Jason Statham                  33.0   \n",
       "4            NaN         Clea DuVall                  23.0   \n",
       "\n",
       "  freebase_char_actor_map_id freebase_character_id freebase_actor_id  Fame  \\\n",
       "0                 /m/0bgchxw            /m/0bgcj3x        /m/03wcfv7   0.0   \n",
       "1                  /m/0jys3m            /m/0bgchn4         /m/0346l4   0.0   \n",
       "2                  /m/0jys3g            /m/0bgchn_        /m/01vw26l  93.0   \n",
       "3                 /m/02vchl6            /m/0bgchnq         /m/034hyc  78.0   \n",
       "4                 /m/02vbb3r            /m/0bgchp9         /m/01y9xg   0.0   \n",
       "\n",
       "   Liked  Disliked  Neutral  \n",
       "0    0.0       0.0      0.0  \n",
       "1    0.0       0.0      0.0  \n",
       "2   57.0      11.0     25.0  \n",
       "3   59.0       4.0     14.0  \n",
       "4    0.0       0.0      0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show initial size of character dataframe\n",
    "print(\"Initial size of characters: \"+str(characters.shape))\n",
    "# merge additional info of the actors to the characters dataframe\n",
    "characters = characters.merge(actors_list[['name','Fame','Liked','Disliked','Neutral']], left_on='actor_name', right_on='name', how='left')\n",
    "characters = characters.drop(columns=['name'])\n",
    "# show new size of characters dataframe\n",
    "#print(\"New size of the dataset\"+str(characters.shape))\n",
    "# compute percentage of NaNs in each column\n",
    "#print(\"Percentage of NaNs in each column: \")\n",
    "#print(characters.isnull().sum()/len(characters)*100)\n",
    "#etnicty at 76% missing and gender at 10% missing\n",
    "#to re compute if we remove the movies we don't have the rating for\n",
    "\n",
    "# filter out all the character rows which wikipedia_movie_id is not in the movies dataframe\n",
    "characters = characters[characters.wikipedia_movie_id.isin(movies.wikipedia_id)]\n",
    "\n",
    "# show new size of characters dataframe\n",
    "print(\"New size of the dataset after removing not reviewed movies: \"+str(characters.shape))\n",
    "\n",
    "# compute percentage of NaNs in each column\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(characters.isnull().sum()/len(characters)*100)\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'category', 'winner', 'entity'], dtype='object')\n",
      "Index(['year', 'category', 'winner', 'entity', 'award_cumcount'], dtype='object')\n",
      "Index(['wikipedia_movie_id', 'freebase_movie_id', 'movie_release_date',\n",
      "       'character_name', 'actor_birth', 'actor_gender', 'actor_height',\n",
      "       'actor_etnicity', 'actor_name', 'actor_age_at_release',\n",
      "       'freebase_char_actor_map_id', 'freebase_character_id',\n",
      "       'freebase_actor_id', 'Fame', 'Liked', 'Disliked', 'Neutral'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>year</th>\n",
       "      <th>award_cumcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wikipedia_movie_id freebase_movie_id movie_release_date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "2              975900         /m/03vyhn         2001-08-24   \n",
       "3              975900         /m/03vyhn         2001-08-24   \n",
       "4              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               character_name actor_birth actor_gender  actor_height  \\\n",
       "0                    Akooshay  1958-08-26            F         1.620   \n",
       "1  Lieutenant Melanie Ballard  1974-08-15            F         1.780   \n",
       "2         Desolation Williams  1969-06-15            M         1.727   \n",
       "3          Sgt Jericho Butler  1967-09-12            M         1.750   \n",
       "4             Bashira Kincaid  1977-09-25            F         1.650   \n",
       "\n",
       "  actor_etnicity          actor_name  actor_age_at_release  \\\n",
       "0            NaN      Wanda De Jesus                  42.0   \n",
       "1     /m/044038p  Natasha Henstridge                  27.0   \n",
       "2        /m/0x67            Ice Cube                  32.0   \n",
       "3            NaN       Jason Statham                  33.0   \n",
       "4            NaN         Clea DuVall                  23.0   \n",
       "\n",
       "  freebase_char_actor_map_id freebase_character_id freebase_actor_id  Fame  \\\n",
       "0                 /m/0bgchxw            /m/0bgcj3x        /m/03wcfv7   0.0   \n",
       "1                  /m/0jys3m            /m/0bgchn4         /m/0346l4   0.0   \n",
       "2                  /m/0jys3g            /m/0bgchn_        /m/01vw26l  93.0   \n",
       "3                 /m/02vchl6            /m/0bgchnq         /m/034hyc  78.0   \n",
       "4                 /m/02vbb3r            /m/0bgchp9         /m/01y9xg   0.0   \n",
       "\n",
       "   Liked  Disliked  Neutral  year  award_cumcount  \n",
       "0    0.0       0.0      0.0   NaN             0.0  \n",
       "1    0.0       0.0      0.0   NaN             0.0  \n",
       "2   57.0      11.0     25.0   NaN             0.0  \n",
       "3   59.0       4.0     14.0   NaN             0.0  \n",
       "4    0.0       0.0      0.0   NaN             0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_award_experience = characters.copy()\n",
    "# Keep only rows with award category containing ACTOR or ACTRESS (e.g. ACTOR WITH LEADING ROLE)\n",
    "# and only those who actually won\n",
    "award_actors = awards_actors[awards_actors.winner == True].copy()\n",
    "print(award_actors.columns)\n",
    "\n",
    "# Get cumulative award count per actor (awards won until (excluding) the current award)\n",
    "award_actors['award_cumcount'] = award_actors.groupby('entity').cumcount()\n",
    "print(award_actors.columns)\n",
    "\n",
    "# Convert 'movie_release_date' to datetime for merging, using coerce for unparseable dates\n",
    "# For rows where conversion failed (resulted in NaT), extract the year directly from the string (often just the year is given)\n",
    "# Leaves rows with no data about movie_release_date as NaT\n",
    "characters_award_experience['release_year'] = pd.to_datetime(characters['movie_release_date'], errors='coerce').dt.year\n",
    "characters_award_experience['release_year'] = characters_award_experience['release_year'].fillna(characters_award_experience['movie_release_date'].str.extract(r'(\\d{4})')[0].astype(float))\n",
    "\n",
    "print(characters.columns)\n",
    "\n",
    "# Merge the DataFrames\n",
    "characters_award_experience = pd.merge(characters_award_experience, \n",
    "                     award_actors[['entity', 'year', 'award_cumcount']], \n",
    "                     left_on=['actor_name', 'release_year'], \n",
    "                     right_on=['entity', 'year'], \n",
    "                     how='left')\n",
    "\n",
    "# After merging, 'award_cumcount' will have NaNs for characters whose actors have no awards\n",
    "# We replace these NaNs with 0\n",
    "characters_award_experience['award_cumcount'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop the extra 'entity' column\n",
    "characters_award_experience.drop(columns=['entity', 'release_year'], inplace=True)\n",
    "characters_award_experience.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_movie_id</th>\n",
       "      <th>freebase_movie_id</th>\n",
       "      <th>movie_release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_birth</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_etnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age_at_release</th>\n",
       "      <th>freebase_char_actor_map_id</th>\n",
       "      <th>freebase_character_id</th>\n",
       "      <th>freebase_actor_id</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Disliked</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>movies_cumcount</th>\n",
       "      <th>award_cumcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>78.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112683</th>\n",
       "      <td>30553937</td>\n",
       "      <td>/m/0g9ts5h</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leda Mulholland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0jxtsvw</td>\n",
       "      <td>/m/0jxtsvz</td>\n",
       "      <td>/m/0gbyr6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112684</th>\n",
       "      <td>30553937</td>\n",
       "      <td>/m/0g9ts5h</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>Restaurant Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Harris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0jxtsx5</td>\n",
       "      <td>/m/0jxtsx8</td>\n",
       "      <td>/m/0jxtsxh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112685</th>\n",
       "      <td>30553937</td>\n",
       "      <td>/m/0g9ts5h</td>\n",
       "      <td>1998-03-07</td>\n",
       "      <td>Julia</td>\n",
       "      <td>1975-10-10</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natalie Ramsey</td>\n",
       "      <td>22.0</td>\n",
       "      <td>/m/0jxtsw7</td>\n",
       "      <td>/m/0jxtswb</td>\n",
       "      <td>/m/027dt0m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112686</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1938-11-26</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rich Little</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vbk4r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/03m6t5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112687</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1918-10-02</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Herb Voland</td>\n",
       "      <td>53.0</td>\n",
       "      <td>/m/0ggdv2_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/02qylb9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112688 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wikipedia_movie_id freebase_movie_id movie_release_date  \\\n",
       "0                   975900         /m/03vyhn         2001-08-24   \n",
       "1                   975900         /m/03vyhn         2001-08-24   \n",
       "2                   975900         /m/03vyhn         2001-08-24   \n",
       "3                   975900         /m/03vyhn         2001-08-24   \n",
       "4                   975900         /m/03vyhn         2001-08-24   \n",
       "...                    ...               ...                ...   \n",
       "112683            30553937        /m/0g9ts5h         1998-03-07   \n",
       "112684            30553937        /m/0g9ts5h         1998-03-07   \n",
       "112685            30553937        /m/0g9ts5h         1998-03-07   \n",
       "112686             9971909        /m/02pygw1         1972-09-22   \n",
       "112687             9971909        /m/02pygw1         1972-09-22   \n",
       "\n",
       "                    character_name actor_birth actor_gender  actor_height  \\\n",
       "0                         Akooshay  1958-08-26            F         1.620   \n",
       "1       Lieutenant Melanie Ballard  1974-08-15            F         1.780   \n",
       "2              Desolation Williams  1969-06-15            M         1.727   \n",
       "3               Sgt Jericho Butler  1967-09-12            M         1.750   \n",
       "4                  Bashira Kincaid  1977-09-25            F         1.650   \n",
       "...                            ...         ...          ...           ...   \n",
       "112683                     Barbara         NaN            F           NaN   \n",
       "112684          Restaurant Manager         NaN            M           NaN   \n",
       "112685                       Julia  1975-10-10            F           NaN   \n",
       "112686                         NaN  1938-11-26            M           NaN   \n",
       "112687                         NaN  1918-10-02            M           NaN   \n",
       "\n",
       "       actor_etnicity          actor_name  actor_age_at_release  \\\n",
       "0                 NaN      Wanda De Jesus                  42.0   \n",
       "1          /m/044038p  Natasha Henstridge                  27.0   \n",
       "2             /m/0x67            Ice Cube                  32.0   \n",
       "3                 NaN       Jason Statham                  33.0   \n",
       "4                 NaN         Clea DuVall                  23.0   \n",
       "...               ...                 ...                   ...   \n",
       "112683            NaN     Leda Mulholland                   NaN   \n",
       "112684            NaN        Randy Harris                   NaN   \n",
       "112685            NaN      Natalie Ramsey                  22.0   \n",
       "112686            NaN         Rich Little                  33.0   \n",
       "112687            NaN         Herb Voland                  53.0   \n",
       "\n",
       "       freebase_char_actor_map_id freebase_character_id freebase_actor_id  \\\n",
       "0                      /m/0bgchxw            /m/0bgcj3x        /m/03wcfv7   \n",
       "1                       /m/0jys3m            /m/0bgchn4         /m/0346l4   \n",
       "2                       /m/0jys3g            /m/0bgchn_        /m/01vw26l   \n",
       "3                      /m/02vchl6            /m/0bgchnq         /m/034hyc   \n",
       "4                      /m/02vbb3r            /m/0bgchp9         /m/01y9xg   \n",
       "...                           ...                   ...               ...   \n",
       "112683                 /m/0jxtsvw            /m/0jxtsvz        /m/0gbyr6p   \n",
       "112684                 /m/0jxtsx5            /m/0jxtsx8        /m/0jxtsxh   \n",
       "112685                 /m/0jxtsw7            /m/0jxtswb        /m/027dt0m   \n",
       "112686                 /m/02vbk4r                   NaN         /m/03m6t5   \n",
       "112687                 /m/0ggdv2_                   NaN        /m/02qylb9   \n",
       "\n",
       "        Fame  Liked  Disliked  Neutral  movies_cumcount  award_cumcount  \n",
       "0        0.0    0.0       0.0      0.0              0.0             0.0  \n",
       "1        0.0    0.0       0.0      0.0              0.0             0.0  \n",
       "2       93.0   57.0      11.0     25.0              0.0             0.0  \n",
       "3       78.0   59.0       4.0     14.0              0.0             0.0  \n",
       "4        0.0    0.0       0.0      0.0              0.0             0.0  \n",
       "...      ...    ...       ...      ...              ...             ...  \n",
       "112683   0.0    0.0       0.0      0.0              0.0             0.0  \n",
       "112684   0.0    0.0       0.0      0.0              0.0             0.0  \n",
       "112685   0.0    0.0       0.0      0.0              2.0             0.0  \n",
       "112686   0.0    0.0       0.0      0.0              1.0             0.0  \n",
       "112687   0.0    0.0       0.0      0.0              2.0             0.0  \n",
       "\n",
       "[112688 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add Movie Experience\n",
    "# 1. Clean: Extract Movies from character based df into new df and drop duplicates\n",
    "# 2. Calc cumcount per actor in this seperate df\n",
    "# 3. Left Join seperate df onto original df!\n",
    "# 4. Drop roles of movies we don't look at!\n",
    "\n",
    "characters_movie_exp = characters_award_experience.copy()\n",
    "\n",
    "# Drop characters with no unique identifier for an actor\n",
    "characters_movie_exp = characters_movie_exp.dropna(subset=['freebase_actor_id'])\n",
    "\n",
    "assert characters_movie_exp.freebase_actor_id.isna().sum() == 0, \"Some actors don't have an id\"\n",
    "assert characters_movie_exp.freebase_movie_id.isna().sum() == 0, \"Some movies don't have an id\"\n",
    "\n",
    "# Drop actors that played twice in the same movie\n",
    "characters_movie_exp = characters_movie_exp.drop_duplicates(['freebase_movie_id', 'freebase_actor_id'])\n",
    "\n",
    "#  Get cumulative movie count per actor (movies done until (excluding) the current movie) as a measure of prior experience\n",
    "characters_movie_exp['movies_cumcount'] = characters_movie_exp.groupby(['freebase_actor_id']).cumcount()\n",
    "\n",
    "characters_merged_exp = pd.merge(characters, characters_movie_exp[['freebase_movie_id', 'freebase_actor_id', 'movies_cumcount', 'award_cumcount']], on=['freebase_movie_id', 'freebase_actor_id'], how='left' )\n",
    "\n",
    "# Ensure we have data about the same set of movies to ensure comparability of findings\n",
    "characters_merged_exp = characters_merged_exp[characters_merged_exp['freebase_movie_id'].isin(movies.freebase_id)]\n",
    "characters = characters_merged_exp.copy()\n",
    "display(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update of actors dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of the dataset after removing actors not in characters: (51085, 12)\n",
      "Percentage of NaNs in each column: \n",
      "actor_birth          39.665264\n",
      "actor_gender         13.845552\n",
      "actor_height         82.307918\n",
      "actor_etnicity       89.493981\n",
      "actor_name            0.001958\n",
      "freebase_actor_id     0.001958\n",
      "awards                0.000000\n",
      "count                 0.001958\n",
      "Fame                  0.000000\n",
      "Liked                 0.000000\n",
      "Disliked              0.000000\n",
      "Neutral               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# filter out actors in actors_info that are not in the characters dataframe\n",
    "actors_info_test = actors_info[actors_info.actor_name.isin(characters.actor_name)]\n",
    "# show new size of actors_info dataframe\n",
    "print(\"New size of the dataset after removing actors not in characters: \"+str(actors_info_test.shape))\n",
    "\n",
    "# compute percentage of NaNs in each column\n",
    "print(\"Percentage of NaNs in each column: \")\n",
    "print(actors_info_test.isnull().sum()/len(actors_info_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update of Movies dataset:\n",
    "Adding character info summarized per movie to complete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1355 entries, 0 to 1354\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Actor     1355 non-null   object\n",
      " 1   Fame      1355 non-null   int64 \n",
      " 2   Liked     1355 non-null   int64 \n",
      " 3   Disliked  1355 non-null   int64 \n",
      " 4   Neutral   1355 non-null   int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 53.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11058 entries, 0 to 11057\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   year      11058 non-null  int64 \n",
      " 1   category  11058 non-null  object\n",
      " 2   winner    11058 non-null  bool  \n",
      " 3   entity    11058 non-null  object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 270.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15106 entries, 0 to 32661\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   wikipedia_id   15106 non-null  int64  \n",
      " 1   freebase_id    15106 non-null  object \n",
      " 2   name           15106 non-null  object \n",
      " 3   release_date   15106 non-null  object \n",
      " 4   revenue        3308 non-null   float64\n",
      " 5   runtime        15106 non-null  int64  \n",
      " 6   languages      15106 non-null  object \n",
      " 7   countries      15106 non-null  object \n",
      " 8   genres         15106 non-null  object \n",
      " 9   year_release   15106 non-null  int32  \n",
      " 10  averageRating  15106 non-null  float64\n",
      " 11  numVotes       15106 non-null  float64\n",
      "dtypes: float64(3), int32(1), int64(2), object(6)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112688 entries, 0 to 112687\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   wikipedia_movie_id          112688 non-null  int64  \n",
      " 1   freebase_movie_id           112688 non-null  object \n",
      " 2   movie_release_date          112688 non-null  object \n",
      " 3   character_name              64661 non-null   object \n",
      " 4   actor_birth                 89622 non-null   object \n",
      " 5   actor_gender                104872 non-null  object \n",
      " 6   actor_height                44282 non-null   float64\n",
      " 7   actor_etnicity              25483 non-null   object \n",
      " 8   actor_name                  112431 non-null  object \n",
      " 9   actor_age_at_release        79838 non-null   float64\n",
      " 10  freebase_char_actor_map_id  112688 non-null  object \n",
      " 11  freebase_character_id       64665 non-null   object \n",
      " 12  freebase_actor_id           112500 non-null  object \n",
      " 13  Fame                        112688 non-null  float64\n",
      " 14  Liked                       112688 non-null  float64\n",
      " 15  Disliked                    112688 non-null  float64\n",
      " 16  Neutral                     112688 non-null  float64\n",
      " 17  movies_cumcount             112500 non-null  float64\n",
      " 18  award_cumcount              112500 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(10)\n",
      "memory usage: 16.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# basic info of the data to see changes when cleaning\n",
    "print(actors.info())\n",
    "print(awards.info())\n",
    "print(movies.info())\n",
    "print(characters.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
